# Model diagnostics & comparison

This page showcase the model diagnosis and comparison for the E~max~ model 

```{r}
#| output: FALSE
#| message: FALSE

library(tidyverse)
library(BayesERtools)
library(posterior)
library(tidybayes)
library(bayesplot)
library(loo)
library(here)
library(gt)

theme_set(theme_bw(base_size = 12))
```

```{r}
#| include: FALSE
# Enable colored outputs
source(here("R", "cli_color_text.R"))
```

## Load data

```{r}
#| message: FALSE
d_sim_emax
```

## Fit models

::: {.panel-tabset}

### Sigmoidal E~max~ model

```{r}
set.seed(1234)

ermod_sigemax <- dev_ermod_emax(
  data = d_sim_emax,
  var_resp = "response_1",
  var_exposure = "exposure",
  gamma_fix = NULL
)

ermod_sigemax
```

### Regular E~max~ (γ fixed at 1)

Another model without sigmoidal component; will be used when we do
model comparison.

```{r}
set.seed(1234)

ermod_emax <- dev_ermod_emax(
  data = d_sim_emax,
  var_resp = "response_1",
  var_exposure = "exposure",
  gamma_fix = 1
)

ermod_emax
```

:::

## Parameter summary table

::: {.panel-tabset}

### `posterior` package

```{r}
d_draws_sigemax_summary <-
  summarize_draws(ermod_sigemax)

d_draws_sigemax_summary |>
  gt() |>
  fmt_number(decimals = 2)
```

### Highest density interval

Here is the example of highest-density continuous interval (HDCI) for the median of `ED50`.
See [here](https://mjskay.github.io/ggdist/reference/point_interval.html) for more details.

```{r}
# HDCI of median.ED50
as_draws_df(ermod_sigemax) |>
  tidybayes::spread_rvars(ec50) |>
  tidybayes::median_hdci()
```

:::


## Fitted values

Fitted values without residual errors (i.e. PRED in NONMEM term) can be
extracted with `sim_er()` function. `.epred` is the expected value prediction.
See `?sim_er` for detail.

```{r}
sim_er(ermod_sigemax) |> head()
```

You can specify `output_type = "median_qi"` to get median and quantile
intervals of the prediction.

```{r}
ersim_sigemax_med_qi <-
  sim_er(ermod_sigemax, output_type = "median_qi")

ersim_sigemax_med_qi |>
  arrange(.row) |>
  head() |>
  gt(rownames_to_stub = TRUE) |>
  fmt_number(decimals = 2, columns = -.row)
```


## Diagnostic plots

We use the [`bayesplot` package](https://mc-stan.org/bayesplot/) 
([Cheat sheet](https://rstudio.github.io/cheatsheets/bayesplot.pdf)) 
to visualize the model fit.

### Convergence

Good fit results in:

- Parameter distributions from MCMC chains should overlap
- Trace plots should not show any trend
- `Rhat` close to 1 (e.g. < 1.1)

```{r}
#| label: fig-convergence
#| fig-width: 7
#| fig-height: 5

d_draws_sigemax <- as_draws_df(ermod_sigemax)
mcmc_dens_overlay(d_draws_sigemax)
mcmc_trace(d_draws_sigemax)
mcmc_rhat(rhat(ermod_sigemax$mod$stanfit))
```

### Parameter estimates distribution

::: {.panel-tabset}

#### `mcmc_hist`

```{r}
#| label: fig-mcmc_hist
#| fig-width: 7
#| fig-height: 5

mcmc_hist(d_draws_sigemax)
```

#### Parameter covariance

```{r}
#| label: fig-mcmc_pairs
#| fig.width: 7
#| fig.height: 5

mcmc_pairs(d_draws_sigemax,
  off_diag_args = list(size = 0.5, alpha = 0.25))
```

:::

### GOF plots

::: {.panel-tabset}

#### Obs & Pred vs predictor

```{r}
#| label: fig-idv_vs_pred
#| fig-width: 7
#| fig-height: 5

plot_er(ermod_sigemax, show_orig_data = TRUE)
```

#### Obs vs pred

```{r}
#| label: fig-obs_vs_pred
#| fig.width: 6
#| fig.height: 6

# Preparation for diagnostic plots
ersim_sigemax_med_qi <- sim_er(ermod_sigemax, output_type = "median_qi")

ersim_sigemax_med_qi |>
  ggplot(aes(x = .epred, y = response_1)) +
  geom_abline(linetype = 2, color = "grey") +
  geom_point() +
  geom_errorbarh(aes(xmin = .epred.lower, xmax = .epred.upper), height = 0) +
  labs(title = "Observed vs Predicted",
    x = "Predicted",
    y = "Observed",
    caption = "Symbol: median and 95% credible interval")
```

#### Residuals

```{r}
#| label: fig-residuals
#| fig-width: 7
#| fig-height: 5

ersim_sigemax_w_resid <-
  sim_er(ermod_sigemax) |>
  mutate(.residual = response_1 - .epred) # Add residuals for plotting
ersim_sigemax_w_resid_med_qi <- median_qi(ersim_sigemax_w_resid)

ersim_sigemax_w_resid_med_qi |>
  ggplot(aes(x = .epred, y = .residual)) +
  xlab("Predicted (linear)") +
  ylab("Residuals") +
  geom_point() +
  geom_errorbar(aes(ymin = .residual.lower, ymax = .residual.upper), width = 0) +
  geom_hline(aes(yintercept = 2), lty = 2, colour = "grey70") +
  geom_hline(aes(yintercept = -2), lty = 2, colour = "grey70")
```

#### Q-Q plot of residuals

```{r}
#| label: fig-qq
#| fig-width: 7
#| fig-height: 5

ersim_sigemax_w_resid_med_qi |>
  ggplot(aes(sample = .residual)) +
  geom_qq() +
  geom_qq_line(colour = "steelblue", lty = 2, alpha = 0.4) +
  coord_equal() +
  xlab("Theoretical") +
  ylab("Sample")
```

:::

## Model comparison

You can perform model comparison based on expected log pointwise predictive density (ELPD).
ELPD is the Bayesian leave-one-out estimate (see ?`loo-glossary`).

Higher ELPD is better, therefore E~max~ model with `γ` fixed to be 1 appears better.
However, `elpd_diff` is tiny and smaller than `se_diff` ([see here](https://stats.stackexchange.com/questions/608881/how-to-interpret-elpd-diff-of-bayesian-loo-estimate-in-bayesian-logistic-regress)),
therefore we can consider the difference to be not meaningful.


```{r}
loo_sigemax <- loo(ermod_sigemax)
loo_emax <- loo(ermod_emax)

loo_compare(list(sigemax = loo_sigemax, emax = loo_emax))
```
